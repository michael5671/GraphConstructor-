import os
import networkx as nx
import yaml
import re
from tree_sitter_languages import get_language, get_parser

class PolyglotGraphBuilder:
    def __init__(self, repo_path):
        self.repo_path = repo_path
        self.graph = nx.DiGraph()
        
        # --- C·∫§U H√åNH PARSER CHO T·ª™NG NG√îN NG·ªÆ ---
        # --- C·∫§U H√åNH PARSER ƒê√É S·ª¨A L·ªñI ---
        self.parsers = {
            '.py': {
                'lang': get_language('python'),
                'parser': get_parser('python'),
                'queries': {
                    'defs': """
                        (class_definition name: (identifier) @name) @def.class
                        (function_definition name: (identifier) @name) @def.func
                    """,
                    'calls': """
                        (call function: (identifier) @call) @ref
                        (call function: (attribute attribute: (identifier) @call)) @ref
                    """
                }
            },
            '.yaml': {
                'lang': get_language('yaml'),
                'parser': get_parser('yaml'),
                'queries': {
                    'defs': """
                        (block_mapping_pair key: (flow_node) @name) @def.key
                    """,
                    'calls': "" 
                }
            },
            '.yml': { 'alias': '.yaml' },
            
            # [FIXED] Dockerfile: B·ªè field "image:", ch·ªâ match node con (image_spec)
            'Dockerfile': {
                'lang': get_language('dockerfile'),
                'parser': get_parser('dockerfile'),
                'queries': {
                    'defs': """
                        (from_instruction (image_spec) @name) @def.image
                    """,
                    'calls': ""
                }
            },
            
            # [FIXED] Terraform/HCL: B·ªè field "type:" v√† "labels:", d·ª±a v√†o th·ª© t·ª± node con
            # C·∫•u tr√∫c th∆∞·ªùng l√†: block -> identifier (resource type) -> string_lit (name)
            '.tf': { 
                'lang': get_language('hcl'),
                'parser': get_parser('hcl'),
                'queries': {
                    'defs': """
                        (block 
                            (identifier) @type 
                            (string_lit) @name
                        ) @def.resource
                    """,
                    'calls': ""
                }
            }
        }
        
        # X·ª≠ l√Ω alias (v√≠ d·ª• .yml -> .yaml)
        keys_to_add = {}
        for ext, config in self.parsers.items():
            if 'alias' in config:
                keys_to_add[ext] = self.parsers[config['alias']]
        self.parsers.update(keys_to_add)

    def get_node_id(self, file_path, name, kind=""):
        rel_path = os.path.relpath(file_path, self.repo_path)
        # Clean ID ƒë·ªÉ tr√°nh l·ªói Mermaid/YAML
        clean_name = name.replace('"', '').replace("'", "")
        return f"{rel_path}::{clean_name}"
    def is_valid_identifier(self, name):
        if not name: return False
        # Ch·ªâ ch·∫•p nh·∫≠n ch·ªØ, s·ªë, _, -, . v√† :
        if re.search(r'[^\w\-\.\:]', name): 
            return False
        return True

    # --- [TH√äM M·ªöI] H√†m leo c√¢y ƒë·ªÉ l·∫•y path YAML (a.b.c) ---
    def get_yaml_full_path(self, node, code_bytes):
        path = []
        current_text = code_bytes[node.start_byte:node.end_byte].decode('utf8')
        path.append(current_text)
        
        # Leo ng∆∞·ª£c l√™n cha
        curr = node.parent
        while curr:
            if curr.type == 'block_mapping_pair':
                key_node = curr.child_by_field_name('key')
                if key_node and key_node != node:
                    key_text = code_bytes[key_node.start_byte:key_node.end_byte].decode('utf8')
                    path.insert(0, key_text)
            curr = curr.parent
        return ".".join(path)

    def parse_file(self, file_path):
        filename = os.path.basename(file_path)
        _, ext = os.path.splitext(filename)
        
        # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho Dockerfile
        if filename == 'Dockerfile': config = self.parsers.get('Dockerfile')
        else: config = self.parsers.get(ext)

        if not config: return 

        rel_path = os.path.relpath(file_path, self.repo_path)
        self.graph.add_node(rel_path, type="file", lang=ext or 'docker')

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                code_str = f.read()
            
            # [QUAN TR·ªåNG] Chuy·ªÉn sang bytes ƒë·ªÉ x·ª≠ l√Ω tree-sitter ch√≠nh x√°c v·ªã tr√≠
            code_bytes = bytes(code_str, "utf8")
            tree = config['parser'].parse(code_bytes)
            
            query = config['lang'].query(config['queries']['defs'])
            captures = query.captures(tree.root_node)
            
            # X·ª≠ l√Ω Captures (H·ªó tr·ª£ c·∫£ version c≈© tr·∫£ v·ªÅ list v√† m·ªõi tr·∫£ v·ªÅ dict)
            # N·∫øu captures l√† dict (version m·ªõi), ta convert sang list tuples ƒë·ªÉ loop chung logic
            if isinstance(captures, dict):
                capture_list = []
                for name, nodes in captures.items():
                    for node in nodes:
                        capture_list.append((node, name))
            else:
                capture_list = captures

            for node, capture_name in capture_list:
                if capture_name == 'name': 
                    name = ""
                    # 1. Logic YAML Ph√¢n c·∫•p (database -> database.db_host)
                    if ext in ['.yaml', '.yml']:
                        name = self.get_yaml_full_path(node, code_bytes)
                    else:
                        name = code_bytes[node.start_byte:node.end_byte].decode('utf8')

                    # 2. L√†m s·∫°ch t√™n
                    name = name.replace('"', '').replace("'", "").strip()
                    
                    # 3. L·ªçc r√°c (Lo·∫°i b·ªè 'nt(' ho·∫∑c t√™n bi·∫øn d·ªã d·∫°ng)
                    if not self.is_valid_identifier(name):
                        continue

                    # 4. T·∫°o Node
                    node_id = self.get_node_id(file_path, name)
                    self.graph.add_node(node_id, type="definition", name=name)
                    self.graph.add_edge(rel_path, node_id, relation="contains")
                    
        except Exception as e:
            print(f"L·ªói parse file {rel_path}: {e}")
                    
        except Exception as e:
            print(f"L·ªói parse file {rel_path}: {e}")

    def build_cross_reference(self):
        print("ƒêang ph√¢n gi·∫£i li√™n k·∫øt to√†n b·ªô repo...")
        definitions = {} 
        
        # 1. Indexing: Gom t·∫•t c·∫£ ƒë·ªãnh nghƒ©a l·∫°i
        for node, attr in self.graph.nodes(data=True):
            if attr.get('type') == 'definition':
                name = attr.get('name')
                if name:
                    # L∆∞u t√™n g·ªëc (VD: database.db_host)
                    if name not in definitions: definitions[name] = []
                    definitions[name].append(node)
                    
                    # [QUAN TR·ªåNG] T·∫°o Alias cho c√°c t√™n ph√¢n c·∫•p
                    # Gi√∫p 'db_host' trong main.py t√¨m th·∫•y 'database.db_host' trong yaml
                    if "." in name:
                        leaf_name = name.split(".")[-1]
                        if leaf_name not in definitions: definitions[leaf_name] = []
                        definitions[leaf_name].append(node)

        # 2. Scanning: Qu√©t n·ªôi dung file ƒë·ªÉ t√¨m reference
        file_nodes = [n for n, a in self.graph.nodes(data=True) if a.get('type') == 'file']
        
        for file_node in file_nodes:
            full_path = os.path.join(self.repo_path, file_node)
            try:
                with open(full_path, "r", encoding="utf-8") as f:
                    content = f.read()
                
                for def_name, target_nodes in definitions.items():
                    # Rule: T√™n ph·∫£i d√†i > 3 k√Ω t·ª± v√† xu·∫•t hi·ªán trong content
                    if len(def_name) > 3 and def_name in content:
                        for target_node in target_nodes:
                            # Kh√¥ng t·ª± n·ªëi ch√≠nh n√≥
                            if not target_node.startswith(file_node):
                                self.graph.add_edge(file_node, target_node, relation="references")
            except:
                pass

    def build(self):
        for root, _, files in os.walk(self.repo_path):
            # B·ªè qua git, venv
            if '.git' in root or 'venv' in root or '__pycache__' in root:
                continue
            for file in files:
                self.parse_file(os.path.join(root, file))
        
        self.build_cross_reference()
        print(f"Build xong! Nodes: {self.graph.number_of_nodes()}, Edges: {self.graph.number_of_edges()}")

    def export_mermaid(self):
        lines = ["flowchart TD"]
        
        def clean_id(text):
            return text.replace("/", "_").replace(".", "_").replace(":", "_").replace("-", "_").replace(" ", "_")

        # 1. V·∫Ω Subgraphs (M·ªói file l√† 1 c·ª•m)
        files = [n for n, a in self.graph.nodes(data=True) if a.get('type') == 'file']
        
        for f in files:
            f_id = clean_id(f)
            lang = self.graph.nodes[f].get('lang', '')
            lines.append(f'    subgraph cluster_{f_id} ["{os.path.basename(f)} ({lang})"]')
            
            # V·∫Ω 1 node "Neo" ƒë·∫°i di·ªán cho ch√≠nh file ƒë√≥ (ƒë·ªÉ n·ªëi d√¢y reference t·ª´ file n√†y ƒëi ra)
            lines.append(f'        {f_id}["üìÑ {os.path.basename(f)}"]')
            lines.append(f'        style {f_id} fill:#f9f,stroke:#333,stroke-width:2px')

            # V·∫Ω c√°c Definitions b√™n trong
            children = [v for u, v, d in self.graph.out_edges(f, data=True) if d['relation'] == 'contains']
            for child in children:
                c_id = clean_id(child)
                c_name = self.graph.nodes[child]['name']
                # Icon t√πy lo·∫°i
                icon = "üîß" if lang == '.py' else "üê≥" if lang == 'Dockerfile' else "‚öôÔ∏è"
                lines.append(f'        {c_id}("{icon} {c_name}")')
                # N·ªëi node File -> node Definition (quan h·ªá ch·ª©a)
                lines.append(f'        {f_id} --- {c_id}')
            
            lines.append('    end')

        # 2. V·∫Ω Reference (Li√™n k·∫øt gi·ªØa c√°c file)
        # Logic: File A (node neo) --> Definition B (node con c·ªßa file kh√°c)
        for u, v, d in self.graph.edges(data=True):
            if d['relation'] == 'references':
                u_id = clean_id(u) # ID c·ªßa File ngu·ªìn
                v_id = clean_id(v) # ID c·ªßa Def ƒë√≠ch
                lines.append(f'    {u_id} -.-> {v_id}')

        return "\n".join(lines)
    
    def export_yaml_whole_repo(self, include_source=True): # Th√™m tham s·ªë include_source
        """Xu·∫•t YAML k√®m theo Source Code ƒë·ªÉ LLM review ƒë∆∞·ª£c"""
        repo_data = []
        file_nodes = [n for n, a in self.graph.nodes(data=True) if a.get('type') == 'file']
        
        for f_node in file_nodes:
            file_path = os.path.join(self.repo_path, f_node)
            
            # ƒê·ªçc n·ªôi dung file (n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu)
            source_content = ""
            if include_source:
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        source_content = f.read()
                except:
                    source_content = "[Binary or Unreadable]"

            file_entry = {
                "path": f_node,
                # Nh√∫ng code v√†o ƒë√¢y ƒë·ªÉ LLM ƒë·ªçc
                "source_code": source_content, 
                "definitions": [],
                "references_to": []
            }
            
            # ... (Ph·∫ßn logic l·∫•y definitions v√† references gi·ªØ nguy√™n) ...
            children = [v for u, v, d in self.graph.out_edges(f_node, data=True) if d['relation'] == 'contains']
            for child in children:
                file_entry["definitions"].append(self.graph.nodes[child]['name'])

            refs = [v for u, v, d in self.graph.out_edges(f_node, data=True) if d['relation'] == 'references']
            for ref in refs:
                ref_name = self.graph.nodes[ref].get('name', ref)
                file_entry["references_to"].append(ref_name)
            
            # Clean up empty lists
            if not file_entry["definitions"]: del file_entry["definitions"]
            if not file_entry["references_to"]: del file_entry["references_to"]
            
            repo_data.append(file_entry)
            
        return yaml.dump(repo_data, sort_keys=False, allow_unicode=True)
if __name__ == "__main__":
    # Thay ƒë∆∞·ªùng d·∫´n t·ªõi repo c·ªßa b·∫°n
    REPO_PATH = "./simpler_repo/mini_polyglot_repo" 
    
    builder = PolyglotGraphBuilder(REPO_PATH)
    builder.build()
    
    # L∆∞u ra file ƒë·ªÉ feed cho LLM
    with open("whole_repo_context.yaml", "w", encoding="utf-8") as f:
        f.write(builder.export_yaml_whole_repo())

    # 2. Xu·∫•t Mermaid ƒë·ªÉ xem h√¨nh
    mermaid_code = builder.export_mermaid()
    with open("repo_graph.mmd", "w", encoding="utf-8") as f:
        f.write(mermaid_code)
    
    print("ƒê√£ xu·∫•t file: whole_repo_context.yaml")
    print("\nCopy n·ªôi dung file .mmd v√†o https://mermaid.live ƒë·ªÉ xem bi·ªÉu ƒë·ªì!")